{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import scipy\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# a function for plotting digitization coordinates\n",
    "def plot_digipoints(digitization_montage, subject, scatter=False):\n",
    "    channel_names = list(digitization_montage.keys())\n",
    "    digipoints = list(digitization_montage.values())\n",
    "    digi_x = [p[0] for p in digipoints]\n",
    "    digi_y = [p[1] for p in digipoints]\n",
    "    digi_z = [p[2] for p in digipoints]\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection':'3d'})\n",
    "    ax.set_title(subject)\n",
    "    if not scatter:\n",
    "        ax.plot(digi_x, digi_y, digi_z)\n",
    "    else:\n",
    "        ax.scatter(digi_x, digi_y, digi_z)\n",
    "    for p1, p2, p3, label in zip(digi_x, digi_y, digi_z, channel_names):\n",
    "        ax.text(p1,p2,p3,label)\n",
    "    ax.set_axis_off()\n",
    "    ax.xaxis.pane.fill=False\n",
    "    ax.yaxis.pane.fill=False\n",
    "    ax.zaxis.pane.fill=False\n",
    "    ax.grid(False)\n",
    "\n",
    "def plot_digipoints2d(digitization_montage, subject):\n",
    "    ch_montage = {key:val for key, val in digitization_montage.items() if key not in ['nas','lpa','rpa']}\n",
    "    montage = mne.channels.make_dig_montage(ch_pos=ch_montage, nasion=digitization_montage['nas'], lpa=digitization_montage['lpa'], rpa=digitization_montage['rpa'])\n",
    "    fig = mne.viz.plot_montage(montage)\n",
    "    fig.suptitle(subject)\n",
    "\n",
    "\n",
    "#Functions for reading digitization coordinates from .nbe and .xml files.\n",
    "#Also includes functions for correcting them\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "def read_digitization_xml(filepath, save_to_dir=None, subject_identifier=None):\n",
    "    digitization_montage = {}\n",
    "    # parse the xml file and loop through it\n",
    "    tree = ET.parse(filepath)\n",
    "    coordinate_space = tree.getroot().get('coordinateSpace')\n",
    "    if coordinate_space not in ['RAS','LPS']:\n",
    "        return False\n",
    "    if coordinate_space=='LPS':\n",
    "        print(f\"detected LPS system in {filepath}, transforming to RAS later...\")\n",
    "    for marker in tree.getroot():\n",
    "        point_name= marker.attrib['description'] #name of the electode or the anatomical landmark\n",
    "        #get the digitization coordinate in the order of x-y-z\n",
    "        colvec = marker.find('ColVec3D')\n",
    "        #set to float and divide by 1000 to scale from millimeters to meters\n",
    "        digitization_coordinate = np.array([float(colvec.get('data0')),float(colvec.get('data1')) ,float(colvec.get('data2'))])/1000\n",
    "        if coordinate_space == 'LPS': #transform then to RAS\n",
    "            digitization_coordinate = np.matmul(digitization_coordinate, np.array([[-1, 0, 0], [0, -1, 0], [0, 0, 1]]))\n",
    "        if point_name == \"NAS\":\n",
    "            point_name = 'nas'\n",
    "        if point_name == \"RTR\":\n",
    "            point_name = 'rpa'\n",
    "        if point_name == \"LTR\":\n",
    "            point_name = 'lpa'\n",
    "        digitization_montage[point_name] = digitization_coordinate #set the point with the data\n",
    "    if save_to_dir and subject_identifier: #save the information\n",
    "        np.save(f'{save_to_dir}/{subject_identifier}_original_digitizations', digitization_montage)\n",
    "    return digitization_montage\n",
    "\n",
    "\n",
    "def read_digitization_nbe(filepath_to_read, save_to_dir=None, subject_identifier=None, correct_point_order_path=None, use_scalp_landmarks=False):\n",
    "    if correct_point_order_path and not isinstance(correct_point_order_path,list):\n",
    "        point_order = np.load(correct_point_order_path) #digitization order\n",
    "    elif isinstance(correct_point_order_path,list): #chieti specification\n",
    "        point_order  = correct_point_order_path\n",
    "    else:\n",
    "        print(\"correct_point_order_path not specified so can not know order of digitization points\")\n",
    "        return False\n",
    "    number_of_points_to_record = len(point_order)\n",
    "    file = open(filepath_to_read,\"r\",encoding= 'unicode_escape')\n",
    "    lines = file.readlines()\n",
    "    for ind1, origline in enumerate(lines): #go through all lines in the file\n",
    "        if \"coordinate system\" in str(origline).lower():\n",
    "            print(str(origline))\n",
    "            if \"mri coordinate system\" not in str(origline).lower():\n",
    "                print(\"coordinate system should be MRI coordinate system, check the .nbe log.\")\n",
    "                return False\n",
    "        if use_scalp_landmarks and \"Landmarks (mm)\" in origline:\n",
    "            lpa, rpa, nas =  False, False, False\n",
    "            for line in lines[ind1:]:\n",
    "                line_splitted = line.split(\"\\t\") #split the line to a list\n",
    "                if \"Scalp landmark: Left ear\" in line:\n",
    "                    lpa = np.array([float(line_splitted[1]),float(line_splitted[2]),float(line_splitted[3])])/1000\n",
    "                elif \"Scalp landmark: Nose/Nasion\" in line:\n",
    "                    nas = np.array([float(line_splitted[1]),float(line_splitted[2]),float(line_splitted[3])])/1000\n",
    "                elif \"Scalp landmark: Right ear\" in line:\n",
    "                    rpa = np.array([float(line_splitted[1]),float(line_splitted[2]),float(line_splitted[3])])/1000\n",
    "                if lpa is not False and rpa is not False and nas is not False:\n",
    "                    break\n",
    "        if \"Digitization Exam Description: \" in str(origline): #find the digitization exam\n",
    "            digitization_montage = {}\n",
    "            digi_ind = 0\n",
    "            #initialize list, dictionary and digi_ind here to always make sure that the last digitization exam is used \n",
    "            for line in lines[ind1:]: #go through the exam\n",
    "                if \"Point\" in line: #only examine lines where a digitization point has been recorded\n",
    "                    line_splitted = line.split(\"\\t\") #split the line to a list\n",
    "                    #get the digitization coordinate (and scale to meters)\n",
    "                    digitization_point =  np.array([float(line_splitted[1]),float(line_splitted[2]),float(line_splitted[3])])/1000\n",
    "                    #align the point with the name of the electode or the anatomical landmark if possible\n",
    "                    if digi_ind < len(point_order):\n",
    "                        point_name = point_order[digi_ind]\n",
    "                        digitization_montage[point_name] = digitization_point\n",
    "                    else:\n",
    "                        faulty_name = f'At_least_bad_{digi_ind}'\n",
    "                        digitization_montage[faulty_name] = digitization_point\n",
    "                    digi_ind += 1\n",
    "    #combine the information and save\n",
    "    if use_scalp_landmarks:\n",
    "        digitization_montage['lpa'] = lpa\n",
    "        digitization_montage['nas'] = nas\n",
    "        digitization_montage['rpa'] = rpa\n",
    "    number_of_recorded_points = len(list(digitization_montage.values()))\n",
    "    if number_of_points_to_record != number_of_recorded_points:\n",
    "        print(f'Recorded points in {filepath_to_read} is {number_of_recorded_points} even though it should be {number_of_points_to_record}')\n",
    "    if save_to_dir and subject_identifier:  #save the information\n",
    "        np.save(f'{save_to_dir}/{subject_identifier}_original_digitizations', digitization_montage)\n",
    "    return digitization_montage\n",
    "\n",
    "def detect_outliers_by_label(dictionaries, subjects, threshold=3):\n",
    "    grouped_points = {}\n",
    "    grouped_points_orig = {}\n",
    "    for d in dictionaries:\n",
    "        positions = np.array([pos for _, pos in d.items()])\n",
    "        meanpos = np.mean(positions,axis=0)\n",
    "        norm_of_maximums = np.linalg.norm(np.max(positions, axis=0))\n",
    "        #print(norm_of_maximums)\n",
    "        #print(meanpos)\n",
    "        for label, pos in d.items():\n",
    "            origpos = pos\n",
    "            pos =  pos - meanpos\n",
    "            pos = pos/norm_of_maximums\n",
    "            if label not in grouped_points:\n",
    "                grouped_points[label] = []\n",
    "                grouped_points_orig[label] = []\n",
    "            grouped_points[label].append(pos) #add the position under the label\n",
    "            grouped_points_orig[label].append(origpos) #add the position under the label\n",
    "    \n",
    "    outliers = {} # init dict for outliers\n",
    "\n",
    "    for label, points in grouped_points.items():\n",
    "        points_arr = np.array(points)\n",
    "        points_orig = np.array(grouped_points_orig[label])\n",
    "\n",
    "        #calculate mean and sd\n",
    "        mean = np.mean(points_arr, axis=0)\n",
    "        sd = np.std(points_arr, axis=0)\n",
    "\n",
    "        label_outliers = [] #init a list for outliers for this label\n",
    "\n",
    "        for index, point in enumerate(points_arr): #go through all points and calculate z-scores and compare to threshold\n",
    "            z_score = (point - mean) / sd\n",
    "            if np.any(np.abs(z_score) > threshold):\n",
    "                label_outliers.append((subjects[index], points_orig[index], point, mean, sd))\n",
    "\n",
    "        if len(label_outliers) > 0:\n",
    "            outliers[label] = label_outliers\n",
    "\n",
    "    return outliers\n",
    "\n",
    "def find_nearest_labels(locations, k):\n",
    "    labels = list(locations.keys())\n",
    "    coords = np.array(list(locations.values()))\n",
    "    distances =  cdist(coords,coords)\n",
    "    nearest = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        nearest_inds = np.argsort(distances[i])[1:k+1]\n",
    "        nearest[label] = set(labels[j] for j in nearest_inds)\n",
    "    return nearest\n",
    "\n",
    "def check_nearest_consistency(dictionaries, k, threshold):\n",
    "    all_nearest = [find_nearest_labels(d,k=k) for d in dictionaries]\n",
    "    outliers = {}\n",
    "    for label in all_nearest[0].keys():\n",
    "        nearest_sets = [nearest[label] for nearest in all_nearest]\n",
    "        common_neighbors = set.intersection(*nearest_sets)\n",
    "        if len(common_neighbors) < threshold:\n",
    "            outliers[label] = {'common_neighbors':common_neighbors, 'neighbor_sets': nearest_sets}\n",
    "        #if len(set(map(frozenset,nearest_sets))) > 1:\n",
    "            #outliers[label]=nearest_sets\n",
    "    return outliers\n",
    "\n",
    "def get_default_channel_pos(default_channel_locations_file, bad_position_names, channel_order, use_fiducials=False):\n",
    "    default_locations = mne.channels.read_custom_montage(default_channel_locations_file)\n",
    "    default_positions = {}\n",
    "    bad_positions = {}\n",
    "    #go through the default channel positions\n",
    "    default_channel_locations_names = default_locations.ch_names\n",
    "    for pos_index, digipoint in enumerate(default_locations.dig):\n",
    "        pos_name_ident = str(digipoint['ident'])\n",
    "        if use_fiducials:\n",
    "            if \"LPA\" in pos_name_ident :\n",
    "                pos_name = \"lpa\"\n",
    "            elif \"RPA\" in pos_name_ident :\n",
    "                pos_name = \"rpa\"\n",
    "            elif \"NASION\" in pos_name_ident:\n",
    "                pos_name = \"nas\"\n",
    "            else:\n",
    "                pos_name = default_channel_locations_names[pos_index-3]\n",
    "        else:\n",
    "            pos_name = default_channel_locations_names[pos_index-3]\n",
    "        if pos_name in channel_order: #if the channel is in the currently used channel order list\n",
    "            position_default = digipoint['r']\n",
    "            default_positions[pos_name] = position_default\n",
    "            if pos_name in bad_position_names:\n",
    "                #position of the bad electrode in default channel positions\n",
    "                bad_positions[pos_name] = position_default\n",
    "    return default_positions, bad_positions\n",
    "\n",
    "\n",
    "def recover_bad_digi_coordinates(bad_electrodes_in_default, good_point_positions, default_point_positions, good_point_positions_full=False):\n",
    "    good_positions = np.array(list(good_point_positions.values())) #good positions of electrodes\n",
    "    default_channel_positions_good = {label:value for label, value in default_point_positions.items() if label not in bad_electrodes_in_default.keys()}\n",
    "    default_positions = np.array(list(default_channel_positions_good.values()))\n",
    "\n",
    "    # center the coordinate systems to the same mean and get the scale between the coordinate systems and apply scaling\n",
    "    centered_good_points = good_positions-np.mean(good_positions,axis=0)\n",
    "    centered_good_default_points = default_positions-np.mean(default_positions,axis=0)\n",
    "    mean_norm_good_pos = np.mean(np.linalg.norm(centered_good_points,axis=1))\n",
    "    mean_norm_default_pos = np.mean(np.linalg.norm(centered_good_default_points,axis=1))\n",
    "    scale = mean_norm_good_pos/mean_norm_default_pos\n",
    "\n",
    "    #get the rotation matrix\n",
    "    r, _ = scipy.spatial.transform.Rotation.align_vectors(centered_good_points, centered_good_default_points)\n",
    "    R = r.as_matrix()\n",
    "\n",
    "    #compute translation\n",
    "    t = np.mean(good_positions, axis=0) - scale*np.dot(np.mean(default_positions,axis=0),R) #times scale?\n",
    "\n",
    "    #construct the transformation matrix\n",
    "    T = np.eye(4)\n",
    "    T[:3,:3] = scale*R\n",
    "    T[:3,3] = t\n",
    "    if good_point_positions_full is not False:\n",
    "        good_point_positions = good_point_positions_full\n",
    "    return recover_positions(bad_electrodes_in_default,T, good_point_positions)\n",
    "\n",
    "\n",
    "def recover_positions(bad_electrodes_in_default,T, good_point_positions):\n",
    "    #transform the bad electrodes from the default coordinates to the head of the subject\n",
    "    for bad_electrode in bad_electrodes_in_default:\n",
    "        if bad_electrode in good_point_positions:\n",
    "            print(\"Bad electrode can not be in good electrodes\")\n",
    "            return False\n",
    "        point_homogeneous = np.append(bad_electrodes_in_default[bad_electrode],1)\n",
    "        good_point_positions[bad_electrode] = np.dot(T,point_homogeneous)[:3] #apply transformation\n",
    "\n",
    "    return good_point_positions\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitizations_path = r\"D:\\REFTEP_ALL\\Digitization/\"\n",
    "default_channel_locations_file = os.path.join(digitizations_path,'standard_1005.elc')\n",
    "\n",
    "\n",
    "point_order_aalto = ['Fp1','Fpz','Fp2','AF7','AF3','AFz','AF4','AF8','F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
    "                        'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8','T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
    "                        'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8','P7','P5','P3','P1','Pz','P2','P4','P6','P8',\n",
    "                        'PO7','PO3','POz','PO4','PO8','O1','Oz','O2','Iz','ref','lpa','nas','rpa'] #this is the electrode path that should be taken\n",
    "digitizations_aalto = r\"D:\\REFTEP_ALL\\Digitization\\Digitizations_Aalto/\"\n",
    "correct_point_order_path_aalto = os.path.join(digitizations_aalto, \"correct_point_order_Aalto\")\n",
    "#np.save(correct_point_order_path_aalto, point_order_aalto)\n",
    "\n",
    "point_order_paths = {'Aalto':f'{correct_point_order_path_aalto}.npy'}\n",
    "runtue = False #whether to run the sites electrode alignemnt\n",
    "runaalto = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtue:\n",
    "    site = 'Tuebingen'\n",
    "    filepath = rf\"D:\\REFTEP_ALL\\Neuronavigation_nexstim_localite\\{site}_localite/\"\n",
    "    identifier = \"EEGMarkers\" #used to identify correct files\n",
    "    digitizations_site = os.path.join(digitizations_path,f'Digitizations_{site}')\n",
    "    for subject in os.listdir(filepath):\n",
    "        if \"stimulation_times\" not in subject:\n",
    "            digitization_folder = os.path.join(filepath, subject, 'EEG')\n",
    "            files_in_digitization_folder = os.listdir(digitization_folder)\n",
    "            #get the EEG marker files\n",
    "            eeg_marker_files = [file for file in files_in_digitization_folder if file.startswith(identifier)]\n",
    "            #get the most recent file\n",
    "            most_recent_file = max(eeg_marker_files, key=lambda file:file[len(identifier):])\n",
    "            #define the filepath and read the digitization file\n",
    "            eeg_marker_filepath = os.path.join(digitization_folder,most_recent_file)\n",
    "            if \"rep\" in subject: #create a new subject identifier\n",
    "                subject_identifier_new = f'REFTEP{subject[-7:]}'\n",
    "            else:\n",
    "                subject_identifier_new = f'REFTEP{subject[-3:]}'\n",
    "            subject_directory_digitization = os.path.join(digitizations_site, subject_identifier_new)\n",
    "            if not os.path.exists(subject_directory_digitization):\n",
    "                os.mkdir(subject_directory_digitization)\n",
    "            digimontage = read_digitization_xml(eeg_marker_filepath, save_to_dir=subject_directory_digitization, subject_identifier=subject_identifier_new)\n",
    "            plot_digipoints(digimontage, subject_identifier_new, scatter=True)\n",
    "    subject_dirs = os.listdir(digitizations_site)\n",
    "    subject_dirs2 = [directory for directory in subject_dirs if \"REFTEP\" in directory]\n",
    "    dictionaries = [np.load(f'{digitizations_site}/{subject}/{subject}_original_digitizations.npy',allow_pickle=True).item() for subject in subject_dirs2]\n",
    "    outliers = detect_outliers_by_label(dictionaries,subject_dirs2,3) #check for outliers\n",
    "    print(\"Outliers found:\", len(outliers))\n",
    "    for outlier in outliers:\n",
    "        print(outlier, outliers[outlier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'Tuebingen'\n",
    "filepath = rf\"D:\\REFTEP_ALL\\Neuronavigation_nexstim_localite\\{site}_localite/\"\n",
    "identifier = \"EEGMarkers\" #used to identify correct files\n",
    "digitizations_site = os.path.join(digitizations_path,f'Digitizations_{site}')\n",
    "subs = []\n",
    "dictionaries = []\n",
    "for subject in os.listdir(filepath):\n",
    "    if \"stimulation_times\" not in subject:\n",
    "        subs.append(subject)\n",
    "        digitization_folder = os.path.join(filepath, subject, 'EEG')\n",
    "        files_in_digitization_folder = os.listdir(digitization_folder)\n",
    "        #get the EEG marker files\n",
    "        eeg_marker_files = [file for file in files_in_digitization_folder if file.startswith(identifier)]\n",
    "        #get the most recent file\n",
    "        most_recent_file = max(eeg_marker_files, key=lambda file:file[len(identifier):])\n",
    "        #define the filepath and read the digitization file\n",
    "        eeg_marker_filepath = os.path.join(digitization_folder,most_recent_file)\n",
    "        if \"rep\" in subject: #create a new subject identifier\n",
    "            subject_identifier_new = f'REFTEP{subject[-7:]}'\n",
    "        else:\n",
    "            subject_identifier_new = f'REFTEP{subject[-3:]}'\n",
    "        subject_directory_digitization = os.path.join(digitizations_site, subject_identifier_new)\n",
    "        digimontage = read_digitization_xml(eeg_marker_filepath, save_to_dir=None, subject_identifier=None)\n",
    "        plot_digipoints2d(digimontage, subject_identifier_new)\n",
    "        dictionaries.append(digimontage)\n",
    "outliers = detect_outliers_by_label(dictionaries,subs,3)\n",
    "print(\"Outliers found:\", len(outliers))\n",
    "for outlier in outliers:\n",
    "    print(outlier, outliers[outlier])\n",
    "\n",
    "#check outliers based on neighbors\n",
    "outliers_pos = check_nearest_consistency(dictionaries, k=8, threshold=5)\n",
    "if outliers_pos:\n",
    "    print(\"outliers found based on neighbors\")\n",
    "    for label, data in outliers_pos.items():\n",
    "        print(f'{label} has outliers')\n",
    "        print(f\"common neighbors:{sorted(data['common_neighbors'])}\")\n",
    "        for i, nearest in enumerate(data['neighbor_sets']):\n",
    "            print(f'dict {i+1}: {nearest}')\n",
    "else:\n",
    "    print(\"no outliers found based on neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runaalto:\n",
    "    site = 'Aalto'\n",
    "    filepath = rf\"D:\\REFTEP_ALL\\Neuronavigation_nexstim_localite\\{site}_nexstim/\"\n",
    "    identifier = \".nbe\" #used to identify correct files\n",
    "    digitizations_site = os.path.join(digitizations_path,f'Digitizations_{site}')\n",
    "    for subject in os.listdir(filepath):\n",
    "        if \"stimulation_times\" not in subject:\n",
    "            nbe_folder = os.path.join(filepath, subject)\n",
    "            files_in_nbe_folder = os.listdir(nbe_folder)\n",
    "            #get the nexstim .nbe file\n",
    "            nbe_files = [file for file in files_in_nbe_folder if file.endswith(identifier)]\n",
    "            if len(nbe_files) > 1:\n",
    "                print(\"More than 1 .nbe file. Check again!\")\n",
    "                break\n",
    "            #get the most recent file\n",
    "            #define the filepath and read the digitization file\n",
    "            nbe_filepath = os.path.join(nbe_folder,nbe_files[0])\n",
    "            subject_identifier_new = f'REFTEP{subject[-3:]}'\n",
    "            subject_directory_digitization = os.path.join(digitizations_site, subject_identifier_new)\n",
    "            if not os.path.exists(subject_directory_digitization):\n",
    "                os.mkdir(subject_directory_digitization)\n",
    "            if \"117\" in subject: #fiducials not recorded in digimontage, so use the recorded scalp marks for nasion and ears\n",
    "                use_scalp_landmarks = True\n",
    "            else:\n",
    "                use_scalp_landmarks = False\n",
    "            digimontage = read_digitization_nbe(nbe_filepath, save_to_dir=subject_directory_digitization, subject_identifier=subject_identifier_new,\n",
    "                                                 correct_point_order_path=point_order_paths[site], use_scalp_landmarks=use_scalp_landmarks)\n",
    "            plot_digipoints(digimontage, subject_identifier_new)\n",
    "\n",
    "\n",
    "    print(site)\n",
    "    subject_dirs = os.listdir(digitizations_site)\n",
    "    subject_dirs = [directory for directory in subject_dirs if \"REFTEP\" in directory and os.path.isdir(os.path.join(digitizations_site,directory)) and '119' not in directory]\n",
    "    dictionaries = [np.load(f'{digitizations_site}/{subject}/{subject}_original_digitizations.npy',allow_pickle=True).item() for subject in subject_dirs]\n",
    "    outliers = detect_outliers_by_label(dictionaries,subject_dirs)\n",
    "\n",
    "    print(\"Outliers found (note that these may not be all the mistakes):\", len(outliers))\n",
    "    for outlier in outliers: #check outliers\n",
    "        print(outlier, outliers[outlier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added information on bad digitization points to excel files\n",
    "## Now the bad points will be adjusted/corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runaalto:\n",
    "    filepath = r\"D:\\REFTEP_ALL\\Digitization\\Digitizations_Aalto\"\n",
    "    corrections_filename = \"digitization_corrections_aalto.xlsx\"\n",
    "    df = pd.read_excel(os.path.join(filepath,corrections_filename))\n",
    "    identifier = \"_original_digitizations.npy\" #used to identify correct files\n",
    "    final_original_digitizations_filename = \"_final_original_digitizations\"\n",
    "    final_corrected_digitizations_filename = \"_final_corrected_digitizations\"\n",
    "    final_digitizations_filename = \"_final_digitizations\"\n",
    "    correct_point_order = np.load(f'{correct_point_order_path_aalto}.npy') #aalto-specific\n",
    "    use_fiducials = False\n",
    "    exclusions = ['ref','rpa','lpa','nas']\n",
    "    %matplotlib qt\n",
    "    for file in os.listdir(filepath):\n",
    "        if \"REFTEP\" in file and '119' not in file: #only check subjects but not REFTEP119\n",
    "            subject = file\n",
    "            digitization_folder = os.path.join(filepath, subject)\n",
    "            files_in_digitization_folder = os.listdir(digitization_folder)\n",
    "            #get the nexstim .nbe file\n",
    "            original_digitization_files = [file for file in files_in_digitization_folder if file.endswith(identifier) and \"final\" not in file]\n",
    "            if len(original_digitization_files ) > 1:\n",
    "                print(\"More than 1 original file for digitization information. Check again!\")\n",
    "                break\n",
    "            #get the most recent file\n",
    "            #define the filepath and read the digitization file\n",
    "            subject_information = df[df.iloc[:,0] == subject]\n",
    "            digitized_order = subject_information['Digitized_order']\n",
    "            bad_positions = subject_information['Bad_or_missing_locations']\n",
    "            digitization_filepath = os.path.join(digitization_folder,original_digitization_files[0])\n",
    "            digitization_montage = np.load(digitization_filepath, allow_pickle=True).item()\n",
    "            if digitized_order.isna().any() and bad_positions.isna().any():\n",
    "                subject_corrected_original_digitizations_filename = subject + final_original_digitizations_filename\n",
    "                #print(f\"{subject} seems to have ok original digitization. Saving the identical file as {subject_corrected_original_digitizations_filename}\")\n",
    "                np.save(os.path.join(digitization_folder,subject_corrected_original_digitizations_filename),digitization_montage)\n",
    "            else:\n",
    "                digivalues = list(digitization_montage.values()) #values in the recorded digitization montage\n",
    "                digitized_order = digitized_order.values.tolist()\n",
    "                bad_positions = bad_positions.values.tolist()\n",
    "                digitized_order = ast.literal_eval(digitized_order[0])\n",
    "                bad_positions = ast.literal_eval(bad_positions[0])\n",
    "                if \"117\" in subject:\n",
    "                    digitized_order = digitized_order + ['lpa','nas','rpa'] #not in digimontage but from anatomical landmarks\n",
    "                digitization_montage_not_nones = {key:value for key, value in zip(digitized_order,digivalues) if key}\n",
    "                #plot_digipoints(digitization_montage_not_nones,subject)\n",
    "                digimontage_real_order = {key:digitization_montage_not_nones[key] for key in correct_point_order if key not in bad_positions and key != \"ref\"}\n",
    "                #plot_digipoints(digimontage_real_order,subject)\n",
    "                default_positions, bad_positions_in_default = get_default_channel_pos(default_channel_locations_file, bad_positions, correct_point_order, use_fiducials=use_fiducials)\n",
    "                #plot_digipoints(default_positions, subject)\n",
    "                dafault_channel_names = list(default_positions.keys())\n",
    "                good_positions = {label:value for label, value in digimontage_real_order.items() if label not in bad_positions and label not in exclusions}\n",
    "                digitization_positions = recover_bad_digi_coordinates(bad_positions_in_default, good_positions, default_positions)\n",
    "                if \"121\" in subject: #manual adjustment after reco\n",
    "                    digitization_positions['TP8'] = [digitization_positions['TP8'][0]+0.0065,digitization_positions['TP8'][1],digitization_positions['TP8'][2]]\n",
    "                if \"120\" in subject: #manual adjustment after reco\n",
    "                    digitization_positions['T8'] = [digitization_positions['T8'][0]-0.008,digitization_positions['T8'][1],digitization_positions['T8'][2]]\n",
    "                electrode_pos_in_correct_order = {label: (digitization_positions[label] if label not in exclusions else digimontage_real_order[label]) for label in correct_point_order if label !='ref'}\n",
    "                digitization_montage = electrode_pos_in_correct_order\n",
    "                plot_digipoints(digitization_montage, subject)\n",
    "                subject_corrected_original_digitizations_filename = subject + final_corrected_digitizations_filename\n",
    "                np.save(os.path.join(digitization_folder,subject_corrected_original_digitizations_filename),digitization_montage)\n",
    "            digitization_montage = {key:digitization_montage[key] for key in digitization_montage.keys() if key != 'ref'} #drop ref\n",
    "            #plot_digipoints(digitization_montage, subject)\n",
    "            subject_final_digitizations_filename = subject + final_digitizations_filename\n",
    "            np.save(os.path.join(digitization_folder,subject_final_digitizations_filename),digitization_montage)\n",
    "        \n",
    "        #plot_digipoints(digimontage, subject)\n",
    "    subject_dirs = os.listdir(filepath)\n",
    "    subject_dirs2 = [directory for directory in subject_dirs if \"REFTEP\" in directory and os.path.isdir(os.path.join(filepath,directory)) and '119' not in directory and '112' not in directory]\n",
    "    dictionaries = [np.load(f'{filepath}/{subject}/{subject}{final_digitizations_filename}.npy',allow_pickle=True).item() for subject in subject_dirs2]\n",
    "    outliers = detect_outliers_by_label(dictionaries,subject_dirs2,3)\n",
    "    #check outliers again\n",
    "    print(\"Outliers found:\", len(outliers))\n",
    "    for outlier in outliers:\n",
    "        print(outlier, outliers[outlier])\n",
    "\n",
    "    outliers_pos = check_nearest_consistency(dictionaries, k=8, threshold=5)\n",
    "    if outliers_pos:\n",
    "        print(\"outliers found based on neighbors\")\n",
    "        for label, data in outliers_pos.items():\n",
    "            print(f'{label} has outliers')\n",
    "            print(f\"common neighbors:{sorted(data['common_neighbors'])}\")\n",
    "            for i, nearest in enumerate(data['neighbor_sets']):\n",
    "                print(f'dict {i+1}: {nearest}')\n",
    "    else:\n",
    "        print(\"no outliers found based on neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runaalto: #plot subjects that you want to inspect more\n",
    "    for subject in subject_dirs:\n",
    "        if '114' in subject or '125' in subject:\n",
    "            dictio =  np.load(f'{filepath}/{subject}/{subject}{final_digitizations_filename}.npy',allow_pickle=True).item()\n",
    "            plot_digipoints(dictio, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_with_digitization=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load epochs files and set the digitization montages to them and save as .fif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil #set the subject-specific electrode positions to the montage to later create the head<->MRI transform and forward model\n",
    "if ready_with_digitization:\n",
    "    failed=False\n",
    "    for site in ['Aalto']:\n",
    "        filepath = rf\"D:\\REFTEP_ALL\\Digitization\\Digitizations_{site}\"\n",
    "        subjects_eeg_directory = rf\"D:\\REFTEP_ALL\\EEG_preprocessing_data\\Preprocessing_{site}\"\n",
    "        source_site = rf\"D:\\REFTEP_ALL\\Source_analysis\\Source_analysis_{site}\"\n",
    "        os.makedirs(source_site, exist_ok=True)\n",
    "        for subject in os.listdir(subjects_eeg_directory):\n",
    "            if subject not in ['sub-105','sub-110','sub-118','sub-120']:\n",
    "                continue\n",
    "            eeg_filename = f\"{subject}_EEG_aligned_final.set\"\n",
    "            eeg_filepath = os.path.join(subjects_eeg_directory,subject,eeg_filename)\n",
    "            reftep_subject = 'REFTEP' + str(subject.split(\"-\")[-1])\n",
    "            if site==\"Aalto\":\n",
    "                final_digitizations_filename = \"_final_digitizations\"\n",
    "                digimontage = np.load(f'{filepath}/{reftep_subject}/{reftep_subject}{final_digitizations_filename}.npy',allow_pickle=True).item()\n",
    "            elif site=='Tuebingen':\n",
    "                digimontage = np.load(f'{filepath}/{reftep_subject}/{reftep_subject}_original_digitizations.npy',allow_pickle=True).item()\n",
    "            else:\n",
    "                failed = True\n",
    "                break\n",
    "            sourcepath_subject = os.path.join(source_site,subject)\n",
    "            if not os.path.exists(sourcepath_subject):\n",
    "                    os.mkdir(sourcepath_subject)\n",
    "            eeg_filepath_fif = os.path.join(sourcepath_subject,f\"{subject}_final_eeg-epo.fif\")\n",
    "            epochs = mne.io.read_epochs_eeglab(eeg_filepath)\n",
    "            #epochs.info['dig'] = None #clear the current default channel location information\n",
    "            default = epochs.info['dig']\n",
    "            ch_montage = {key:val for key, val in digimontage.items() if key not in ['nas','lpa','rpa'] and key in epochs.info['ch_names']}\n",
    "            digitization_montage = mne.channels.make_dig_montage(ch_pos=ch_montage, nasion=digimontage['nas'], lpa=digimontage['lpa'], rpa=digimontage['rpa'])\n",
    "            epochs.set_montage(digitization_montage) #set the digitization montage to the object\n",
    "            epochs.set_eeg_reference(ref_channels='average',projection=True) #add average reference projection to tell mne that it has been applied (already done in matlab before), applying it later again is not a problem\n",
    "            real = epochs.info['dig']\n",
    "            for digip in real:\n",
    "                if digip in default:\n",
    "                    print(\"FAILED\")\n",
    "                    failed = True\n",
    "                    break\n",
    "            epochs.save(eeg_filepath_fif,overwrite=True)\n",
    "        if failed:\n",
    "            print(\"FAILED\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
