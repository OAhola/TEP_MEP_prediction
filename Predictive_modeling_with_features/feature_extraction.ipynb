{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import mne_connectivity\n",
    "import os\n",
    "import pactools\n",
    "\n",
    "def extract_features(data, sfreq, freq_ranges, bw_scales, use_psd, use_pac, use_wpli, feature_path, subject):\n",
    "    freqs_arrays = {}\n",
    "    for freq_ind, (freq_identifier,(fmin, fmax)) in enumerate(freq_ranges.items()):\n",
    "        psds, freqs, bw = get_bandpowers(data, fmin, fmax, sfreq, bw_scales[freq_identifier])\n",
    "        f_bins = np.arange(fmin + bw/2,fmax,bw)\n",
    "        freqs_arrays[freq_identifier] = f_bins\n",
    "        print(f_bins)\n",
    "        if use_psd:\n",
    "            bandpowers = np.mean(psds,axis=2)\n",
    "            #print(bandpowers.shape)\n",
    "            filepath_bandpowers = os.path.join(feature_path,f\"{subject}_{freq_identifier}_bandpowers\")\n",
    "            np.save(filepath_bandpowers, bandpowers)\n",
    "        if use_wpli['bool']: #do connectivity or not\n",
    "            n_cycles = use_wpli['n_cycles'][freq_identifier] #number of cycles to use for this freq band\n",
    "            con = get_con(data,freqs, sfreq, n_cycles)\n",
    "            filepath_wplis = os.path.join(feature_path,f\"{subject}_{freq_identifier}_wplis\")\n",
    "            con.save(filepath_wplis, con) #save the con\n",
    "    if use_pac['bool']: #calculate pac or not\n",
    "        for freq_ind1, freq_identifier1 in enumerate(list(freq_ranges.keys())):\n",
    "            for freq_ind2, freq_identifier2 in enumerate(list(freq_ranges.keys())):\n",
    "                if freq_ind1 < freq_ind2:\n",
    "                    freqs_1 = freqs_arrays[freq_identifier1] #freqs lower\n",
    "                    freqs_2 = freqs_arrays[freq_identifier2] #freqs upper\n",
    "                    pac = get_pac(data, sfreq, freqs_1, freqs_2) #get the pac\n",
    "                    filepath_pacs_now = os.path.join(feature_path,f\"{subject}_{freq_identifier1}-{freq_identifier2}_pac\")\n",
    "                    np.save(filepath_pacs_now,pac) #save the pac\n",
    "\n",
    "def get_bandpowers(data,fmin,fmax,sfreq, bw_scale):\n",
    "    n_times = data.shape[-1] #number of time points\n",
    "    bw = bw_scale * (sfreq / n_times) #used bandwidth\n",
    "    psds, freqs = mne.time_frequency.psd_array_multitaper(data, sfreq, fmin=fmin, fmax=fmax, bandwidth=bw, output='power')\n",
    "    return psds, freqs, bw\n",
    "\n",
    "def get_con(data,freqs,sfreq,n_cycles): #get connectivity as wpli\n",
    "    con = mne_connectivity.spectral_connectivity_time(data, freqs=freqs, method='wpli', average=False, mode='multitaper',sfreq=sfreq, faverage=True,n_cycles=n_cycles,verbose=False,n_jobs=1)\n",
    "    return con\n",
    "\n",
    "def get_pac(data, sfreq, freqs_lower, freqs_upper):\n",
    "    comods = []\n",
    "    n_trials, n_pos, n_times = data.shape #n_pos is number of labels or number of channels\n",
    "    for trial_ind in range(n_trials):\n",
    "        data_trial = data[trial_ind,:,:] #data at this trial\n",
    "        chans_pacs_trials = []\n",
    "        for ch_ind in range(n_pos): #go over all pos (channels or labels)\n",
    "            ch_data_trial = data_trial[ch_ind,:] #data of this pos in this trial\n",
    "            estimator = pactools.Comodulogram(fs=sfreq, low_fq_range=freqs_lower, high_fq_range=freqs_upper, method='tort',progress_bar=False, random_state=42, n_jobs=1) #fix random state for consistency\n",
    "            estimator.fit(ch_data_trial) #fit data\n",
    "            chans_pacs_trials.append(estimator.comod_)\n",
    "        comods.append(np.array(chans_pacs_trials))\n",
    "    return np.array(comods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from queue import Queue\n",
    "import logging\n",
    "\n",
    "def process_subject(source_site, features_site, subject, typenow, use_pac, use_wpli, use_psd, bw_scales, fr_names, tmin, tmax):\n",
    "    try:\n",
    "        logging.info(f\"Processing {subject}\")\n",
    "        sourcepath_subject = os.path.join(source_site,subject)\n",
    "        featurepath_subject = os.path.join(features_site,subject,typenow)\n",
    "\n",
    "        if typenow == 'source_depth0.8': #then load source estimates (labelled)\n",
    "            for parctype in [str(['n15', 'p30', 'n45', 'p60', 'handknob']),'aparc']:\n",
    "                featurepath_subject_parctype = os.path.join(featurepath_subject,str(subject + \"_\" + parctype))\n",
    "                epochs_filepath = os.path.join(sourcepath_subject,f'{subject}_final_eeg-epo.fif')\n",
    "                source_estimates_path_subject = os.path.join(sourcepath_subject,f'{subject}_stcs_in_fsaverage_{parctype}_depth0.8')\n",
    "                n_files = len([file for file in os.listdir(source_estimates_path_subject) if f\"fsaverage_{parctype}_epoch\" in file]) #number of files of this type in the folder\n",
    "                data_all = np.array([np.load(os.path.join(source_estimates_path_subject,f\"{subject}-fsaverage_{parctype}_epoch_{k}.npy\")) for k in range(n_files)]) #load all data\n",
    "                epochs = mne.read_epochs(epochs_filepath) #get the respective epochs info for reading the sampling freq\n",
    "                times = epochs.times\n",
    "                indices = np.array([index for index in range(len(times)) if tmin <= times[index] <= tmax]) #indices to use from source estimates\n",
    "                data = data_all[:,:,indices]\n",
    "                sfreq = epochs.info['sfreq'] #used sampling frequency\n",
    "                #print(data.shape) #trials x labels x timepoints\n",
    "\n",
    "                os.makedirs(featurepath_subject_parctype, exist_ok=True) #make dir if needed\n",
    "\n",
    "                freq_range_dict = np.load(os.path.join(features_site,subject,f'{subject}-freq_ranges_dict.npy'),allow_pickle=True).item()\n",
    "                freq_ranges = {fr_name:freq_range_dict[fr_name] for fr_name in fr_names} #do not take alpha peak or the boolean related to it\n",
    "\n",
    "                extract_features(data, sfreq, freq_ranges, bw_scales, use_psd, use_pac, use_wpli, featurepath_subject_parctype, subject)\n",
    "            logging.info(f\"Completed processing {subject}\")\n",
    "        else:\n",
    "            print(\"wrong typenow (only source curretly)\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing subject {subject}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fr_names = ['theta','alpha','beta','gamma']\n",
    "use_pac = {'bool':False}\n",
    "use_wpli = {'bool':False, 'n_cycles':{'theta':1, 'alpha':5, 'beta':7, 'gamma':7}} #whether to calculate wpli or not and the associated n_cycles values for each freq band\n",
    "bw_scales = {'theta':2, 'alpha':2, 'beta':3, 'gamma':6} #scales for calculating bandwidths for different freq ranges\n",
    "use_psd = True\n",
    "#define data cropping times\n",
    "tmin = -1.015\n",
    "tmax = -0.015\n",
    "#max_workers = 26 #n workers\n",
    "\n",
    "\n",
    "for typenow in ['source_depth0.8']:\n",
    "    for siteind, site in enumerate(['Tuebingen','Aalto']):\n",
    "        source_site = rf\"D:\\REFTEP_ALL\\Source_analysis\\Source_analysis_{site}\"\n",
    "        features_site = rf\"D:\\REFTEP_ALL\\Features_v2\\Features_{site}\"\n",
    "        subjects = [dirname for dirname in os.listdir(source_site) if \"sub\" in dirname]\n",
    "        for subject in subjects:\n",
    "            process_subject(source_site, features_site, subject, typenow, use_pac, use_wpli, use_psd, bw_scales, fr_names, tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
