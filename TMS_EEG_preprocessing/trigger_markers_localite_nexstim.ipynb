{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "from collections import Counter\n",
    "import scipy\n",
    "import pandas as pd\n",
    "    \n",
    "def get_trigger_marker_info_xml(filepath_trigger_markers, filepath_instrument_markers, constrain_recording_time=True, start_id=0):\n",
    "    #first read the instrument marker\n",
    "    instrument_marker = get_instrument_marker_information(filepath_instrument_markers)\n",
    "    date_of_instrument_marker_file = filepath_instrument_markers.split('InstrumentMarker')[-1][:-4]\n",
    "    time_string = date_of_instrument_marker_file[8:10] + \":\" + date_of_instrument_marker_file[10:12]+ \":\" + date_of_instrument_marker_file[12:14] + \".\" + date_of_instrument_marker_file[14:17]\n",
    "    instrument_marker_time = convert_time_to_ms(time_string,type_of_time=0)\n",
    "\n",
    "    tree_triggers = ET.parse(filepath_trigger_markers)\n",
    "    date_of_trigger_markers_file = filepath_trigger_markers.split('_Coil')[-1][2:-4]\n",
    "    if not date_of_instrument_marker_file[:8] == date_of_trigger_markers_file[:8]: #then we have the same yyyy:mm:dd for both files and we can compare times\n",
    "        print(f\"Different dates in instrument markers and trigger markers!\\nCheck files {filepath_trigger_markers} and {filepath_instrument_markers} again!\")\n",
    "        return False\n",
    "\n",
    "    root_triggers = tree_triggers.getroot()\n",
    "    starting_time = root_triggers.get('startTime') # in hours:minutes:seconds:milliseconds, e.g. 12:24:06.283 starts at 24 minutes, 6 seconds and 283 milliseconds after 12 pm (noon).\n",
    "    starting_time_in_ms = convert_time_to_ms(starting_time,type_of_time=0) #starting time of the marker file in milliseconds in day time\n",
    "    coordinate_space_triggers = root_triggers.get('coordinateSpace') #coordinate space of the recording. Should be LPS or RAS.\n",
    "    bad_times = []\n",
    "    trigger_markers = [] #initialize list for saving the trigger markers\n",
    "    for trigger_marker in root_triggers.findall(\".//TriggerMarker\"): #go through all trigger markers\n",
    "        recording_time_latency = trigger_marker.get('recordingTime') #get the recording time of the marker\n",
    "        recording_time = starting_time_in_ms + int(recording_time_latency)\n",
    "        if instrument_marker_time < recording_time and constrain_recording_time or (not constrain_recording_time): #constrain the recording time to take only into account those stimuli after which the target did not change.\n",
    "            matrix_element = trigger_marker.find('Matrix4D') #get the coil information of that trigger marker\n",
    "            if matrix_element is not None: #save the info on the coil position, direction, and orientation\n",
    "                trigger_info = read_localite_matrix4d(matrix_element)\n",
    "                trigger_info['recording_time_latency'] = recording_time_latency #save the time of stimulation relative to the start of the recording\n",
    "                trigger_info['recording_time_in_real_world'] = recording_time\n",
    "                if coordinate_space_triggers =='LPS': #transform everything into ras\n",
    "                    trigger_info = transform_from_lps_to_ras(trigger_info)\n",
    "                    coordinate_space_triggers_now = 'RAS' #new coordinate space\n",
    "                elif coordinate_space_triggers =='RAS':\n",
    "                    coordinate_space_triggers_now = 'RAS'\n",
    "                else:\n",
    "                    print(\"Bad coordinate system in trigger markers! Should be LPS or RAS.\")\n",
    "                    return False\n",
    "                trigger_info = add_matrix4d(trigger_info)\n",
    "                trigger_info['stimulus_id'] = start_id + len(trigger_markers)\n",
    "                #trigger_info = calculate_pcd_and_dir_diff(trigger_info, instrument_marker)\n",
    "                if coordinate_space_triggers_now == 'RAS':\n",
    "                    trigger_markers.append(trigger_info)\n",
    "                else:\n",
    "                    print(\"Bad coordinate system in trigger markers! Should be LPS or RAS.\")\n",
    "                    return False\n",
    "        elif constrain_recording_time and instrument_marker_time > recording_time:\n",
    "            bad_times.append(recording_time)\n",
    "    if constrain_recording_time and len(bad_times) > 0:\n",
    "        print(f'Did not save {len(bad_times)} stimuli because the instrument marker was modified after that they were delivered.')\n",
    "    print(f'Stimuli read: {len(trigger_markers)}.')\n",
    "\n",
    "    #add time information to the instrument marker too\n",
    "    instrument_marker['recording_time'] = instrument_marker_time\n",
    "    instrument_marker['recording_date'] = date_of_instrument_marker_file\n",
    "    information = {'trigger_markers':trigger_markers, 'instrument_marker':instrument_marker, 'starting_time_of_trigger_marker_recording':starting_time}\n",
    "    return information\n",
    "\n",
    "def convert_time_to_ms(time_string, type_of_time):\n",
    "    if type_of_time == 0:\n",
    "        #assumes format hours:minutes:seconds.milliseconds\n",
    "        hours, minutes, seconds_milliseconds =  time_string.split(\":\")\n",
    "        seconds, milliseconds = seconds_milliseconds.split(\".\")\n",
    "        time_in_ms = (int(hours)*60*60*1000) + (int(minutes)*60*1000) + (int(seconds)*1000) + int(milliseconds)\n",
    "    else:\n",
    "        #assumes format hours:minutes:seconds\n",
    "        hours, minutes, seconds =  time_string.split(\":\")\n",
    "        time_in_ms = (int(hours)*60*60*1000) + (int(minutes)*60*1000) + (int(seconds)*1000)\n",
    "    return time_in_ms\n",
    "\n",
    "\n",
    "def get_instrument_marker_information(filepath_instrument_markers):\n",
    "    tree_instruments = ET.parse(filepath_instrument_markers)\n",
    "    root_instruments = tree_instruments.getroot()\n",
    "    coordinate_space_instruments = root_instruments.get('coordinateSpace') #Should be LPS or RAS.\n",
    "    selected_instrument_markers = []\n",
    "    for instrument_marker_candidate in root_instruments.findall(\".//InstrumentMarker[@selected='true']\"):\n",
    "        matrix_element = instrument_marker_candidate.find('.//Matrix4D')\n",
    "        if matrix_element is not None:\n",
    "            instrument_marker = read_localite_matrix4d(matrix_element)\n",
    "            if coordinate_space_instruments == 'LPS': #transform from lps to ras\n",
    "                instrument_marker = transform_from_lps_to_ras(instrument_marker)\n",
    "                coordinate_space_instruments = 'RAS' #new coordinate space\n",
    "            instrument_marker = add_matrix4d(instrument_marker)\n",
    "            if coordinate_space_instruments == 'RAS':\n",
    "                selected_instrument_markers.append(instrument_marker)\n",
    "            else:\n",
    "                print(\"Bad coordinate system in instrument markers! Should be LPS or RAS.\")\n",
    "                return False\n",
    "    if len(selected_instrument_markers) != 1: #there should only be one selected instrument marker\n",
    "        print(\"More or less than one selected instrument marker. Check again!\")\n",
    "        return False\n",
    "    else:\n",
    "        return instrument_marker\n",
    "    \n",
    "\n",
    "def read_localite_matrix4d(matrix_element):\n",
    "    # see the localite documentation for more\n",
    "    data = {name: np.float64(value) for name, value in matrix_element.attrib.items()}\n",
    "    marker_info = {}\n",
    "    marker_info['coil_normal'] = np.array([data['data00'],data['data10'],data['data20']])\n",
    "    marker_info['coil_dir'] = np.array([data['data01'],data['data11'],data['data21']])\n",
    "    marker_info['coil_ori'] = np.array([data['data02'],data['data12'],data['data22']])\n",
    "    marker_info['coil_pos'] = np.array([data['data03'],data['data13'],data['data23']])\n",
    "    return marker_info\n",
    "\n",
    "def add_matrix4d(marker_info):\n",
    "    #add the matrix to the marker info\n",
    "    marker_info['matrix'] = np.eye(4)\n",
    "    marker_info['matrix'][0:3,0] = marker_info['coil_normal']\n",
    "    marker_info['matrix'][0:3,1] = marker_info['coil_dir']\n",
    "    marker_info['matrix'][0:3,2] = marker_info['coil_ori']\n",
    "    marker_info['matrix'][0:3,3] = marker_info['coil_pos']\n",
    "    return marker_info\n",
    "\n",
    "\n",
    "def transform_from_lps_to_ras(information_dict):\n",
    "    #transform from lps to ras (switch order of x and y coordinates)\n",
    "    transformation_matrix = np.array([[-1, 0, 0], [0, -1, 0], [0, 0, 1]])\n",
    "    for spatial_key in ['coil_pos', 'coil_ori', 'coil_normal','coil_dir']: #transform the features to RAS that have spatial information in them\n",
    "        information_dict[spatial_key] = np.matmul(transformation_matrix,information_dict[spatial_key])\n",
    "    return information_dict #return the modified dictionary\n",
    "\n",
    "\n",
    "def get_instrument_marker_filepath(subject_localite_path):\n",
    "    insturment_marker_folder_path = os.path.join(subject_localite_path, 'InstrumentMarkers')\n",
    "    files_in_instument_marker_folder = os.listdir(insturment_marker_folder_path)\n",
    "    #get the instrument marker files\n",
    "    identifier = 'InstrumentMarker'\n",
    "    instrument_marker_files = [file for file in files_in_instument_marker_folder if file.startswith(identifier)]\n",
    "    #get the most recent file (compare dates) that are e.g. \"InstrumentMarker20240210114243703.xml\"\n",
    "    most_recent_file = max(instrument_marker_files, key=lambda file:file[len(identifier):])\n",
    "    #define the filepath and read the digitization file\n",
    "    instrument_marker_filepath = os.path.join(insturment_marker_folder_path,most_recent_file)\n",
    "    return instrument_marker_filepath\n",
    "\n",
    "\n",
    "def get_trigger_marker_filepath(subject_localite_path):\n",
    "    trigger_marker_folder_path = os.path.join(subject_localite_path, 'TMSTrigger')\n",
    "    try:\n",
    "        files_in_trigger_marker_folder = os.listdir(trigger_marker_folder_path)\n",
    "        #get the instrument marker files\n",
    "        identifier = 'TriggerMarkers'\n",
    "        trigger_marker_files = [file for file in files_in_trigger_marker_folder if file.startswith(identifier)]\n",
    "        all_dates = [int(file.split(\"_Coil\")[-1][2:10]) for file in trigger_marker_files]\n",
    "        latest_date = np.max(all_dates)\n",
    "        #get the largest file that is in the group of the latest date\n",
    "        trigger_marker_filepaths = [os.path.join(trigger_marker_folder_path,trigger_marker_file) for trigger_marker_file in trigger_marker_files if str(latest_date) in trigger_marker_file and \"Coil1\" in trigger_marker_file]\n",
    "        trigger_markers_filepaths = [fp for fp in trigger_marker_filepaths if os.path.getsize(fp) > 2000]\n",
    "        sorted_trigger_markers_filepaths = sorted(trigger_markers_filepaths, key=lambda x: int(x[-21:-4]))\n",
    "        return sorted_trigger_markers_filepaths\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No TMSTrigger folder exists in {subject_localite_path}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_trigger_marker_info_nbe(filepath, subject):\n",
    "    file = open(filepath,\"r\",encoding= 'unicode_escape')\n",
    "    lines = file.readlines()\n",
    "    sequence_starts = []\n",
    "    line_index = 0\n",
    "    trigger_markers = []\n",
    "    target_pos_mte = False\n",
    "    while line_index < len(lines): #go through all lines\n",
    "        line = lines[line_index]\n",
    "        if \"Sequence Created\" in line and \"series\" not in line: #observe stimulation sequences\n",
    "            line_splitted =  line.split(\" \")\n",
    "            date_of_squence = line_splitted[2] + \"T\"\n",
    "            time_of_sequence = line_splitted[3].strip(\"\\n\")\n",
    "            sequence_starts.append(date_of_squence + time_of_sequence)\n",
    "            #get time of the start of the sequence in milliseconds of day time\n",
    "            time_of_sequence_in_ms = convert_time_to_ms(time_of_sequence,type_of_time=1)\n",
    "            #labels = ['ID', 'latency','rep_stim_ID','coil_pos','coil_normal','coil_ori']\n",
    "            if lines[line_index+5].split(\"\\t\") == [\"\\n\"]: #the sequences we are interested in\n",
    "                line_index += 1\n",
    "                candidate_line_splitted = lines[line_index].split(\"\\t\")\n",
    "                while True:\n",
    "                    line_index += 1\n",
    "                    if len(candidate_line_splitted) > 5:\n",
    "                        if candidate_line_splitted[5] =='(ms)':\n",
    "                            break\n",
    "                    candidate_line_splitted = lines[line_index].split(\"\\t\")\n",
    "                line_index += 1\n",
    "                stimulation_line = lines[line_index].split(\"\\t\")\n",
    "                while stimulation_line[0] != \"\\n\": #go through all the stimulation lines in the current sequence and save information\n",
    "                    if stimulation_line[12] != \"-\": #check if x-position is available, then everything regarding positions etc. should also be\n",
    "                        trigger_info = {}\n",
    "                        trigger_info['stimulus_id'] = stimulation_line[2]\n",
    "                        trigger_info['repeated_stimulus_id'] = stimulation_line[9]\n",
    "                        trigger_info['sequence_started'] = sequence_starts[-1]\n",
    "                        trigger_info['recording_time_latency'] = int(stimulation_line[3])\n",
    "                        trigger_info['recording_time_in_real_world'] = time_of_sequence_in_ms + trigger_info['recording_time_latency']\n",
    "                        start_of_coil_pos = 12\n",
    "                        trigger_info['coil_pos'] = np.array([np.float64(stimulation_line[start_of_coil_pos+i]) for i in range(3)])\n",
    "                        start_of_coil_normal = 15\n",
    "                        trigger_info['coil_normal'] = np.array([np.float64(stimulation_line[start_of_coil_normal+i]) for i in range(3)])\n",
    "                        start_of_coil_dir = 18\n",
    "                        trigger_info['coil_dir'] = np.array([np.float64(stimulation_line[start_of_coil_dir+i]) for i in range(3)])\n",
    "                        trigger_markers.append(trigger_info)\n",
    "\n",
    "                    #advance to the next line\n",
    "                    line_index += 1\n",
    "                    stimulation_line = lines[line_index].split(\"\\t\")\n",
    "            else:\n",
    "                line_index += 1\n",
    "        elif \"Motor Threshold Exam Starting stimulus:\" in line:\n",
    "            target_pos_mte = line.split(\" \")[-1].strip(\"\\n\")\n",
    "            print(target_pos_mte)\n",
    "            line_index += 1\n",
    "        else:\n",
    "            line_index += 1\n",
    "\n",
    "\n",
    "    # the target is the one that has been repeated the most (in here, we only had one target for ~1200 stims at the primary motor cortex)\n",
    "    repeated_stimulus_ids = [trigger['repeated_stimulus_id'] for trigger in trigger_markers]\n",
    "    stimulus_counts = Counter(repeated_stimulus_ids)\n",
    "    most_common_repeated_stimulus = stimulus_counts.most_common(1)[0]\n",
    "    most_common_repeated_stimulus_id = most_common_repeated_stimulus[0]\n",
    "    #most_common_repeated_stimulus_count = most_common_repeated_stimulus[1]\n",
    "    print(stimulus_counts)\n",
    "    if target_pos_mte is not False:\n",
    "        if target_pos_mte != most_common_repeated_stimulus_id:\n",
    "            print(f\"pos_id: target pos in rmt definition {target_pos_mte} is different than most common repeated stim {most_common_repeated_stimulus_id}\")\n",
    "            try:\n",
    "                target_marker_most_common = [trigger_info for trigger_info in trigger_markers if trigger_info['stimulus_id'] == most_common_repeated_stimulus_id][0]\n",
    "                target_marker_mte = [trigger_info for trigger_info in trigger_markers if trigger_info['stimulus_id'] == target_pos_mte][0]\n",
    "                print(f\"target pos: target pos rmt definition {target_marker_mte['coil_pos']} is different than most common repeated stim {target_marker_most_common['coil_pos']}\")\n",
    "            except IndexError:\n",
    "                print(\"most_common_repeated_stimulus_id is not a targeted stimulation (no spatial information available)\")\n",
    "                return False\n",
    "    # get the target marker\n",
    "    try:\n",
    "        target_marker = [trigger_info for trigger_info in trigger_markers if trigger_info['stimulus_id'] == most_common_repeated_stimulus_id][0]\n",
    "        #print(target_marker)\n",
    "        targeted_triggers = []\n",
    "        for trigger_marker in trigger_markers:\n",
    "            if trigger_marker['repeated_stimulus_id'] == target_marker['stimulus_id']: #only take the targeted stimuli\n",
    "                #trigger_marker = calculate_pcd_and_dir_diff(trigger_marker, target_marker) #calculate the pcd_pos and the direction difference\n",
    "                targeted_triggers.append(trigger_marker)\n",
    "\n",
    "        information = {'trigger_markers':targeted_triggers, 'target_marker':target_marker, 'sequence_starting_times':sequence_starts}\n",
    "        return information\n",
    "    except IndexError:\n",
    "        print(\"most_common_repeated_stimulus_id is not a targeted stimulation (no spatial information available)\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = rf\"D:\\REFTEP_ALL\\Neuronavigation_nexstim_localite\\Tuebingen_localite/\" #has folders in a structure like subject1, subject2,.., subject_n'\n",
    "filepath_stims = os.path.join(filepath, \"stimulation_times\")\n",
    "os.makedirs(filepath_stims,exist_ok=True)\n",
    "for subject in os.listdir(filepath):\n",
    "    if \"sub-\" in subject: #if there are other files then do not look at them.\n",
    "        print(subject)\n",
    "        subject_localite_path = os.path.join(filepath, subject) #the path of the subject in the localite directory\n",
    "        subject_path_stims = os.path.join(filepath_stims, subject)\n",
    "        #os.makedirs(subject_path_stims,exist_ok=True)\n",
    "        #get the path of the trigger marker file. This file is the LARGEST that exists in .../subject_localite_path/TMSTrigger/ that is in the group of files with the latest date (year, month, day).\n",
    "        #Even though we only used one coil, trigger marker files for both Coil0 and Coil1 have the same date, but one of them is larger.\n",
    "        trigger_markers_filepaths = get_trigger_marker_filepath(subject_localite_path)\n",
    "        next_id = 0\n",
    "        if trigger_markers_filepaths:\n",
    "            for ind, trigger_marker_filepath in enumerate(trigger_markers_filepaths):\n",
    "                next_id += 1\n",
    "                #get the path of the instrument marker file. This file is the MOST RECENT file that exists in .../subject_localite_path/InstrumentMarkers/. This is the one that was most recently updated.\n",
    "                #This file should never change after the actual stimulation is started.\n",
    "                instrument_marker_filepath = get_instrument_marker_filepath(subject_localite_path)\n",
    "                if subject == \"sub-035\":\n",
    "                    constrain_recording_time = True\n",
    "                    instrument_marker_filepath = r\"D:\\REFTEP_ALL\\Neuronavigation_nexstim_localite\\Tuebingen_localite\\sub-035\\InstrumentMarkers\\InstrumentMarker20230328105137090.xml\"\n",
    "                else:\n",
    "                    constrain_recording_time = True\n",
    "                information_new = get_trigger_marker_info_xml(trigger_marker_filepath, instrument_marker_filepath, constrain_recording_time=constrain_recording_time, start_id=next_id) #get the information on trigger markers\n",
    "                if ind > 0:\n",
    "                    for key in ['trigger_markers']:\n",
    "                        information[key] = information[key] + information_new[key]\n",
    "                else:\n",
    "                    information = information_new\n",
    "                next_id = len(information['trigger_markers'])\n",
    "            print(len(information['trigger_markers']))\n",
    "            if len(information['trigger_markers']) != len(np.unique([trig['stimulus_id'] for trig in information['trigger_markers']])):\n",
    "                print(\"bad stim ids\")\n",
    "            np.save(f'{subject_path_stims}/{subject}_stimulations',information)\n",
    "            scipy.io.savemat(f'{subject_path_stims}/{subject}_stimulations.mat',information)\n",
    "            #for trigm in information['trigger_markers']:\n",
    "                #print(trigm['coil_pos'],information['instrument_marker']['coil_pos'])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = rf\"D:\\REFTEP_ALL\\Neuronavigation_nexstim_localite\\Aalto_nexstim/\" #has folders in a structure like subject1, subject2,.., subject_n\n",
    "filepath_stims = os.path.join(filepath, \"stimulation_times\")\n",
    "os.makedirs(filepath_stims,exist_ok=True)\n",
    "for subject in os.listdir(filepath):\n",
    "    if \"REFTEP\" in subject: #if there are other files then do not look at them.\n",
    "        subject_directory_path = os.path.join(filepath, subject)\n",
    "        files_in_dir = os.listdir(subject_directory_path)\n",
    "        nbe_files = [file for file in files_in_dir if file.endswith(\".nbe\")]\n",
    "        subject_path_stims = os.path.join(filepath_stims, subject)\n",
    "        os.makedirs(subject_path_stims,exist_ok=True)\n",
    "        if len(nbe_files) > 1:\n",
    "            print(f\"More than one .nbe file in directory for {subject}\")\n",
    "            break\n",
    "        else:\n",
    "            nbe_file = nbe_files[0]\n",
    "        nbe_filepath = os.path.join(subject_directory_path,nbe_file)\n",
    "        information = get_trigger_marker_info_nbe(nbe_filepath,subject)\n",
    "        n_triggers = len(information['trigger_markers'])\n",
    "        if n_triggers >= 1200:\n",
    "            print(f'{subject} has {n_triggers} targeted stimuli at the most common target. Can include noise masking trials.')\n",
    "        else:\n",
    "            print(f'{subject} has {n_triggers} targeted stimuli at the most common target. Should be at least 1200! Check this!')\n",
    "        np.save(f'{subject_path_stims}/{subject}_stimulations',information)\n",
    "        scipy.io.savemat(f'{subject_path_stims}/{subject}_stimulations.mat',information)\n",
    "        #print(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
